{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OBJECTIVE: Identify good feature subsets using the training dataset and test these subsets on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case I: NONE Feature Selection\n",
    "Here,there's no feature selection strategy is incorporated. \n",
    "\n",
    "All the features are considered while calculating the accuracy on test data as well on train data using hold out and cross validation respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries.\n",
    "\n",
    "import pandas as pd                                         \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data and Test data is read into dataframes train_data and test_data\n",
    "\n",
    "train_data = pd.read_csv('SPECTF_train.csv')\n",
    "test_data =  pd.read_csv('SPECTF_test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target variable DIAGNOSIS is popped from the train as well as test data and stored in y_train and y_test variables.\n",
    "\n",
    "y_train = train_data.pop('DIAGNOSIS')\n",
    "y_test =  test_data.pop('DIAGNOSIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data from train_data and test_data except the DIAGNOSIS column is saved into the X_train and X_test variables respectively.\n",
    "\n",
    "X_train = train_data\n",
    "X_test =  test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the shape of both X_train and X_test data just to ensure they have same number of columns.\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting is a machine learning technique for regression and classification issues \n",
    "that produces a predictive model in the form of a collection of weak predictive models. It builds the model in a stage-wise fashion and generalizes it by allowing optimization of an arbitrary differentiable loss function.\n",
    "\n",
    "The ensemble problem is simplified greedily as a forward stage-wise additive model. \n",
    "We don’t optimize the ensemble in a global manner, but instead seek to improve the result based on the current estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting classifier is built using the GradientBoostingClassifier library from sklearn.ensemble module.\n",
    "# loss is set to deviance for a binary classification (DIAGNOSIS 1/0).\n",
    "# Learning_rate (default 0.1)\n",
    "# random_state is set to 1 so as to reproduce the same output every time it is executed.\n",
    "\n",
    "gbc = GradientBoostingClassifier(loss = 'deviance',learning_rate=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting classifier is used to learn the model parameters using the fit() method.\n",
    "\n",
    "gbc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Test Data using Hold Out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output class(DIAGNOSIS) is predicted for the X_test values using the predict().\n",
    "\n",
    "y_pred_test=gbc.predict(X_test)\n",
    "\n",
    "# Accuracy of predicted values (y_pred_test) with actual values (y_test) is calculated using the accuracy_score() method\n",
    "\n",
    "acc_holdout = accuracy_score(y_pred_test,y_test)\n",
    "print (\"Accuracy with Hold Out method when None features extracted:\", acc_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Train Data using Cross Validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 5 folds (1 Test data and rest 4 are treated as training data), accuracies are computed using the method cross_val_Score()\n",
    "# Here,Cross validation is done on the training data only (Internally it considers 1 part as test and rest as training data)\n",
    "# The classifier it uses to classify the records with DIAGNOSIS as 1 or 0 is GradientBoostingClassifier.\n",
    "scores = cross_val_score(gbc, X_train, y_train, cv=5)\n",
    "\n",
    "# Accumulated accuracy of all the whole training data is computed by taking the mean of the scores\n",
    "acc_cross_val = scores.mean()\n",
    "print (\"Accuracy with Cross-validation method when None features extracted:\", acc_cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_None = pd.DataFrame([[acc_holdout,acc_cross_val]],index=['None'],columns=['Test','Train'])\n",
    "print(df_None)\n",
    "df_None.plot(kind = 'bar',width = 0.3,color= ['red','green'])\n",
    "plt.title('Fig1. Bar graph showing accuracies of both Train and Test Data when None features extracted')\n",
    "plt.xlabel('Feature Selection Strategy: None')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion from Case I: Accuracy generated by K-fold cross validation is higher than that done by hold-out methos on Test data. It is because Cross validation method is more precise but slightly more computationally expensive as it considers every point of the input data as test data once and rest of the times as training data ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case II: Feature Selection using INFORMATION GAIN\n",
    "\n",
    "Information gain (IG) measures how much “information” a feature gives us about the target class.\n",
    "\n",
    "Features out of 44 which are having high mutual dependency with the target variable are extracted first.\n",
    "\n",
    "Then instead of training the model on whole dataset, model is build using only the extracted features.\n",
    "\n",
    "Then classification of unknown values with only extracted features is done.\n",
    "\n",
    "Thus computation complexity reduces as compared to training the model with all the features.\n",
    "\n",
    "In case of a classification task, we measure the dependence between each feature and the target variable. \n",
    "If there exists a dependence, then we extract that feature for our classification tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual dependency between 2 random variables (All the features and target variables) is computed  using the mutual_info_classif()\n",
    "# of feature.selection module.\n",
    "# For every feature, the dependency score is stored in a dictionary.\n",
    "\n",
    "mi = dict()\n",
    "i_scores = mutual_info_classif(X_train, y_train)\n",
    "\n",
    "for i,j in zip(train_data.columns,i_scores):\n",
    "    mi[i]=j\n",
    "\n",
    "# A dataframe from dictionary of mutual dependency score is built and sorted on the basis of i_scores in descending order\n",
    " \n",
    "df_IGain = pd.DataFrame.from_dict(mi,orient='index',columns=['I-Gain'])\n",
    "df_IGain.sort_values(by=['I-Gain'],ascending=False,inplace=True)\n",
    "df_IGain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of all the features along with their dependency score(I-Gain score) is plotted\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize = (12,15))\n",
    "n = len(df_IGain.index)\n",
    "rr = range(1,n)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(df_IGain.index, df_IGain[\"I-Gain\"], label='I-Gain',width=.80)\n",
    "ax.set_xticklabels(list(df_IGain.index), rotation = 90)\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('I-Gain')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select *k* best features\n",
    "\n",
    "We rank the features using information gain (well mutual information) and select the _k_ best to build a classifier.  \n",
    "We iterate through increasing values of *k*.  \n",
    "`SelectKBest` is a _transform_ that transforms the training data.\n",
    "\n",
    "The k best features out of 44 which are having high accuracy from the classifier passed(mutual_info_classif) are extracted. \n",
    "\n",
    "Training and test data is transformed according to the number of features extracted.\n",
    "\n",
    "Then it learns the model parameters.\n",
    "\n",
    "(Hold out Method): Prediction for the class of test data is done using the trained classifier.\n",
    "\n",
    "(Cross Val Method): Cross validation is performed on the training data to calculate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of 44 features,k features are extracted and model parameters are found on X_train and y_train.\n",
    "# Both train and test data are transformed(only k features from both are selected.)\n",
    "# Accuracy is found while predicting the class of transformed X_test with the actual values of target.\n",
    "# For every feature based on mutual_info_classif, accuracy is stored in a dataframe.\n",
    "\n",
    "acc_scores = []\n",
    "for kk in range(1, X_train.shape[1]+1):\n",
    "    FS_trans = SelectKBest(mutual_info_classif,k=kk).fit(X_train, y_train)\n",
    "    X_tR_new = FS_trans.transform(X_train)\n",
    "    X_tS_new = FS_trans.transform(X_test)\n",
    "    \n",
    "    gbc_Igain=gbc.fit(X_tR_new, y_train)\n",
    "    y_pred_Igain = gbc_Igain.predict(X_tS_new)\n",
    "    acc = accuracy_score(y_test, y_pred_Igain)\n",
    "    acc_scores.append(acc)\n",
    "\n",
    "df_IGain['Accuracy'] = acc_scores\n",
    "df_IGain.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A plot with all the features along with their I-Gain score is plotted.\n",
    "# Accuracy values for all the features is plotted (Accuracy at point x comprises the accuracy when all the features preceding x are considered.)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "plt.figure(figsize = (20,20),dpi= 150)\n",
    "n = len(df_IGain.index)\n",
    "rr = range(1,n)\n",
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "ax.bar(df_IGain.index, df_IGain[\"I-Gain\"], label='I-Gain',width=.35)\n",
    "ax2.plot(df_IGain.index, df_IGain[\"Accuracy\"], color='red', label='Accuracy')\n",
    "ax.set_xticklabels(list(df_IGain.index), rotation = 90)\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('I-Gain')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of k selected features is extracted from the dataframe with accuracy value <= index of first occuence of maximum.\n",
    "# idxmax() function returns index of first occurrence of maximum over requested axis.\n",
    "\n",
    "selected_features_list = list(df_IGain[:df_IGain['Accuracy'].idxmax()].index.values)\n",
    "print(selected_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Test Data using Hold Out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the train data comprises of only the selected features out of 44 features.\n",
    "X_train_Igain = X_train[selected_features_list]\n",
    "\n",
    "gbc.fit(X_train_Igain,y_train)\n",
    "\n",
    "# The output class(DIAGNOSIS) is predicted for the X_test values using the predict().\n",
    "y_pred_test_Igain=gbc.predict(X_test[selected_features_list])\n",
    "\n",
    "# Accuracy of predicted values (y_pred_test_Igain) with actual values (y_test) is calculated using the accuracy_score() method\n",
    "acc_holdout_igain = accuracy_score(y_pred_test_Igain,y_test)\n",
    "print (\"Accuracy with Hold Out method when k =\", len(selected_features_list),\"best features extracted:\", acc_holdout_igain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Train Data using Cross Validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 5 folds (1 Test data and rest 4 are treated as training data), accuracies are computed using the method cross_val_Score()\n",
    "# Here,Cross validation is done on the training data only (Internally it considers 1 part as test and rest as training data)\n",
    "# The classifier it uses to classify the records with DIAGNOSIS as 1 or 0 is GradientBoostingClassifier.\n",
    "\n",
    "scores = cross_val_score(gbc, X_train_Igain, y_train, cv=5)\n",
    "\n",
    "# Accumulated accuracy of all the whole training data is computed by taking the mean of the scores\n",
    "acc_cross_val_igain = scores.mean()\n",
    "print (\"Accuracy with Cross-validation method when k =\", len(selected_features_list),\"best features extracted:\", acc_cross_val_igain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_igain = pd.DataFrame([[acc_holdout_igain,acc_cross_val_igain]],index=['Igain'],columns=['Test','Train'])\n",
    "print(df_igain)\n",
    "df_igain.plot(kind = 'bar',width = 0.3,color= ['red','green'])\n",
    "plt.title('Fig2. Bar graph showing accuracies of both Train and Test Data when k features extracted using I-Gain value')\n",
    "plt.xlabel('Feature Selection Strategy: I-Gain')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case III: Feature Selection using Wrapper-based forward sequential search\n",
    "\n",
    "scikit learn does not support Wrapper feature selection so we use MLxtend.\n",
    "\n",
    "Wrapper methods are based on greedy search algorithms as they evaluate all possible combinations of the features\n",
    "and select the combination that produces the best result for a specific machine learning algorithm.\n",
    "\n",
    "Step Forward Feature Selection: In the first phase,the performance of the classifier is evaluated corressponding to each feature. The feature that performs the best is selected out of all the features.\n",
    "\n",
    "Next step, the first feature is tried in combination with all the other features. The combination of two features that yield the best algorithm performance is selected. \n",
    "\n",
    "Similarly, the process continues until the specified number of features are selected.\n",
    "\n",
    "k_features specifies the number of features to select.\n",
    "The forward parameter, if set to True, performs step forward feature selection. \n",
    "The verbose parameter is used for logging the progress of the feature selector.\n",
    "The scoring parameter defines the performance evaluation criteria.\n",
    "Finally, cv refers to cross-validation folds.\n",
    "\n",
    "Thus a feature selector is created using the SFS().\n",
    "Now the fit method is invoked on the feature selector and pass it the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SequentialFeatureSelector is built with estimator as Gradient Boosting Classifier and folds 10 using which model parameters are made using the fit().\n",
    "feature_names = train_data.columns\n",
    "\n",
    "sfs_forward = SFS(gbc, \n",
    "                  k_features=44, \n",
    "                  forward=True, \n",
    "                  floating=False, \n",
    "                  verbose=1,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10, n_jobs = -1)\n",
    "\n",
    "sfs_forward = sfs_forward.fit(X_train, y_train,custom_feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot showing all the features along with their accuracy is shown.\n",
    "# sfs_forward.get_metric_dict() stores pair of(feature and its corresponding standard deviation, cross validation accuracies, average accuracy and so on)\n",
    "\n",
    "fig1 = plot_sfs(sfs_forward.get_metric_dict(),ylabel='Accuracy',kind='std_dev', figsize = (8,5))\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#print(sfs_forward.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(pd.DataFrame(sfs_forward.get_metric_dict()).loc['avg_score'].astype('float64'))\n",
    "num_features = df_res.idxmax()\n",
    "num = int(num_features[0])\n",
    "sfs_forward.subsets_[num]['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum accuracy comes out to be at feature number 7, so k_feature is set to 7 here.\n",
    "# To create forward based selection strategy, the attribute forward is set to True.\n",
    "\n",
    "feature_names = train_data.columns\n",
    "sfs_forward = SFS(gbc, \n",
    "                  k_features=num, \n",
    "                  forward=True, \n",
    "                  floating=False, \n",
    "                  verbose=1,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10, n_jobs = -1)\n",
    "\n",
    "#print(sfs_forward)\n",
    "sfs_forward = sfs_forward.fit(X_train, y_train,custom_feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot showing 7 features from the dictionary (sfs_forward.get_metric_dict()) along with their accuracy is shown.\n",
    "# sfs_forward.get_metric_dict() stores pair of (feature and its corresponding standard deviation, cross validation accuracies, average accuracy and so on)\n",
    "\n",
    "fig1 = plot_sfs(sfs_forward.get_metric_dict(),ylabel='Accuracy',kind='std_dev')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(sfs_forward.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# All the selected combinations of features is shown along with their average_score, feature names and so on are shown using the subsets_ function of SFS.\n",
    "sfs_forward.subsets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Test Data using Hold Out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the train data comprises of only the selected 7 features out of 44 features.\n",
    "\n",
    "selected_features_train = X_train[list(sfs_forward.k_feature_names_)]\n",
    "selected_features_test = X_test[list(sfs_forward.k_feature_names_)]\n",
    "\n",
    "gbc.fit(selected_features_train,y_train)\n",
    "\n",
    "# The output class (DIAGNOSIS) is predicted for the selected features from the X_test values using the predict().\n",
    "y_pred_test_forward=gbc.predict(selected_features_test)\n",
    "\n",
    "# Accuracy of predicted values (y_pred_test_forward) with actual values (y_test) is calculated using the accuracy_score() method\n",
    "\n",
    "acc_holdout_forward = accuracy_score(y_pred_test_forward,y_test)\n",
    "print (\"Accuracy with Hold Out method when k =\", len(selected_features_list),\"best features extracted using SFS:\", acc_holdout_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Train Data using Cross Validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the SFS internally uses cross validation on training data with 10 folds. So k_score_ function is used to find the accuracy of training data when done cross validation on it.\n",
    "# Out of 10, 1 part is considered as test data and rest treated as trainig data.\n",
    "# The classifier it uses to classify the records with DIAGNOSIS as 1 or 0 is GradientBoostingClassifier.\n",
    "# Accumulated accuracy of all the whole training data is computed by taking the mean of the scores.\n",
    "\n",
    "print (\"Accuracy with Cross-validation method when k =\", len(selected_features_list),\"best features extracted using SFS:\", sfs_forward.k_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataframe with columns as Test and Train and index as SFS and values of accuracy with hold out and accuracy with cross val is made\n",
    "# A bar graph showing both the accuracies is plot.\n",
    "df_frwd = pd.DataFrame([[acc_holdout_forward,sfs_forward.k_score_]],index=['SFS'],columns=['Test','Train'])\n",
    "print(df_frwd)\n",
    "df_frwd.plot(kind = 'bar',width = 0.3,color= ['red','green'])\n",
    "plt.title('Fig3. Bar graph showing accuracies of both Train and Test Data when k features extracted using SFS')\n",
    "plt.xlabel('Feature Selection Strategy: Wrapper Based SFS')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case IV: Feature Selection using Wrapper-based backward elimination.\n",
    "\n",
    "scikit learn does not support Wrapper feature selection so we use MLxtend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper based backward elimination is a step backwards feature selection. \n",
    "It is the exact opposite of step forward feature selection.\n",
    "In the first phase, one feature is removed in round-robin fashion from the feature set and the performance of the classifier is evaluated.\n",
    "\n",
    "The feature set that yields the best performance is retained. \n",
    "\n",
    "In the second step, again one feature is removed in a round-robin fashion and the performance of all the combination of features except the 2 features is evaluated. \n",
    "\n",
    "This process continues until the specified number of features remain in the dataset.\n",
    "\n",
    "k_features specifies the number of features to select.\n",
    "The forward parameter, if set to False, performs step backward feature selection. \n",
    "The verbose parameter is used for logging the progress of the feature selector.\n",
    "The scoring parameter defines the performance evaluation criteria.\n",
    "Finally, cv refers to cross-validation folds.\n",
    "\n",
    "Thus a feature selector is created using the SFS(forward = False).\n",
    "Now the fit method is invoked on the feature selector and pass it the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SequentialFeatureSelector is built with estimator as Gradient Boosting Classifier and folds 10 but in backward direction using which model parameters are made using the fit().\n",
    "\n",
    "feature_names = train_data.columns\n",
    "\n",
    "sfs_backward = SFS(gbc, \n",
    "                  k_features=1, \n",
    "                  forward=False, \n",
    "                  floating=False, \n",
    "                  verbose=1,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10, n_jobs = -1)\n",
    "\n",
    "sfs_backward = sfs_backward.fit(X_train, y_train,custom_feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot showing all the features along with their accuracy is shown.\n",
    "# sfs_backward.get_metric_dict() stores pair of(feature and its corresponding standard deviation, cross validation accuracies, average accuracy and so on)\n",
    "\n",
    "fig2 = plot_sfs(sfs_backward.get_metric_dict(),ylabel='Accuracy',kind='std_dev')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title('Sequential Backward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()\n",
    "#print(sfs_backward.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sfs_backward.get_metric_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(pd.DataFrame(sfs_backward.get_metric_dict()).loc['avg_score'].astype('float64'))\n",
    "num_features = df_res[::-1].idxmax()\n",
    "num = int(num_features[0])\n",
    "sfs_backward.subsets_[num]['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum accuracy comes out to be at feature number 16, so k_feature is set to 7 here.\n",
    "# To create backward based selection strategy, the attribute forward is set to False.\n",
    "\n",
    "feature_names = train_data.columns\n",
    "\n",
    "sfs_backward = SFS(gbc, \n",
    "                  k_features=num, \n",
    "                  forward=False, \n",
    "                  floating=False, \n",
    "                  verbose=1,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10, n_jobs = -1)\n",
    "\n",
    "sfs_backward = sfs_backward.fit(X_train, y_train,custom_feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All the selected combinations of features is shown along with their average_score, feature names and so on are shown using the subsets_ function of SFS.\n",
    "sfs_backward.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plot_sfs(sfs_backward.get_metric_dict(),ylabel='Accuracy',kind='std_dev')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title('Sequential Backward Elimination')\n",
    "plt.grid()\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()\n",
    "print(sfs_backward.k_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Test Data using Hold Out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the train data comprises of only the selected 7 features out of 44 features.\n",
    "\n",
    "selected_features_train = X_train[list(sfs_backward.k_feature_names_)]\n",
    "selected_features_test = X_test[list(sfs_backward.k_feature_names_)]\n",
    "\n",
    "\n",
    "gbc.fit(selected_features_train,y_train)\n",
    "\n",
    "# The output class (DIAGNOSIS) is predicted for the selected features from the X_test values using the predict().\n",
    "y_pred_test_backward=gbc.predict(selected_features_test)\n",
    "\n",
    "# Accuracy of predicted values (y_pred_test_backward) with actual values (y_test) is calculated using the accuracy_score() method\n",
    "acc_holdout_backward = accuracy_score(y_pred_test_backward,y_test)\n",
    "print (\"Accuracy with Hold Out method when k =\", len(selected_features_list),\"best features extracted using SFS backward:\", acc_holdout_backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Train Data using Cross Validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the SFS internally uses cross validation on training data with 10 folds. So k_score_ function is used to find the accuracy of training data when done cross validation on it.\n",
    "# Out of 10, 1 part is considered as test data and rest treated as trainig data.\n",
    "# The classifier it uses to classify the records with DIAGNOSIS as 1 or 0 is GradientBoostingClassifier.\n",
    "# Accumulated accuracy of all the whole training data is computed by taking the mean of the scores.\n",
    "\n",
    "print (\"Accuracy with Cross-validation method when k =\", len(selected_features_list),\"best features extracted using SFS backward :\", sfs_backward.k_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataframe with columns as Test and Train and index as SFS_bkwd and values of accuracy with hold out and accuracy with cross val is made\n",
    "# A bar graph showing both the accuracies is plot.\n",
    "\n",
    "df_bkwd = pd.DataFrame([[acc_holdout_backward,sfs_backward.k_score_]],index=['SFS_Backward'],columns=['Test','Train'])\n",
    "print(df_bkwd)\n",
    "df_bkwd.plot(kind = 'bar',width = 0.3,color= ['red','green'])\n",
    "plt.title('Fig4. Bar graph showing accuracies of both Train and Test Data when k features extracted using SFS Backward')\n",
    "plt.xlabel('Feature Selection Strategy: Wrapper Based Backward Elimination')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUMULATIVE REPRESENTATION OF ALL FEATURE SELECTION STRATEGY\n",
    "\n",
    "A dataframe is built with columns as Test and Train and index having all 4 strategy of feature selection (None, I-Gain, SFS Forward, SFS Backward) and values of accuracy with hold out and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[acc_cross_val,acc_holdout],[acc_cross_val_igain,acc_holdout_igain],[sfs_forward.k_score_,acc_holdout_forward],[sfs_backward.k_score_,acc_holdout_backward]],\n",
    "                  index = ['None','I-Gain','Wrapper-F','Wrapper-B'],columns = ['Train','Test'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bar graph showing both the accuracies is plot.\n",
    "\n",
    "df.plot(kind='bar',legend= 'upper right')\n",
    "plt.title('Fig5. Bar graph showing accuracies of Hold Out and Cross Validation of all 4 Feature Selection Strategies.')\n",
    "plt.xlabel('Feature Selection Strategy')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. FILTER METHOD: The Information Gain filter is classifier agnostic pre-selection method which are independent of the machine learning method. This is computationally more efficient but selection of features may depend on the learning algorithm which it ignores.\n",
    "\n",
    "2. WRAPPER METHOD: Wrappers are feedback methods which incorporate the Machine Learning algorithm in the Feature Selection process,i.e they rely on the performance of a specific classifier to evaluate the quality of a set of features. \n",
    "Wrapper methods search through the space of feature subsets and calculate the estimated accuracy of a single learning algorithm for each feature that can be added to or removed from the feature subset. \n",
    "\n",
    "The accuracy on the test data calculated using all 3 feature selection strategies (Information Gain Filter, Wrapper Sequential Forward Selection, Wrapper based Backward elimination) comes to be consistent whereas accuracy on the training dataset is eventually increasing in case of Wrapper methods.\n",
    "\n",
    "The filter method is unstable as compared to the Wrapper based methods because:\n",
    "1. No Model Bias:\n",
    "Different features may suit different learning algorithms but filters do not take this into account.\n",
    "\n",
    "2. No Feature Dependencies:\n",
    "• The features are considered in isolation from one another, and are not considered in context.\n",
    "• In some cases, a filter might select two predictive but correlated features, where one would be sufficient.\n",
    "• In other cases, one feature needs another feature to boost accuracy, but a filter cannot discover this.\n",
    "\n",
    "whereas the Wrapper based methods considers bias into account and considers the features in context.\n",
    "The wrapper method is computationally more demanding, but takes dependencies of the feature subset on the learning algorithm into account.\n",
    "\n",
    "Wrapper based Sequential Forward Selection method is faster than backward elimination technique as it starts with small subsets, so requires less running time if stopped early.\n",
    "1. It starts from 1 feature and goes upto the maximum accuracy bearing features but it's accuracy is less than that of the backward elimination strategy as once it gets the maximum accuracy in between, it will stop considering the next features \n",
    "2. The Wrapper based Backward Elimination strategy is slow but accuracy is high as it starts from combination of all the features calculating the accuracy and removing the feature one by one till no feature left.\n",
    "\n",
    "The discrepancy between the training and test data can be accompanied by two facts:\n",
    "1. The training data set size is not even the half of the test dataset which may lead to overfitting.\n",
    "2. Using features extracted from wrapper methods can lead to overfitting as wrapper methods already train machine learning models with the features and it affects the true power of learning. But the features from filter methods will not lead to overfitting in most of the cases.\n",
    "\n",
    "From the result graph, the accuracy on the test dataset is similar throughout the feature selection strategy but the accuracy on the training dataset in eventually increasing in the case of Wrapper based methods.\n",
    "\n",
    "The insights on data that can be derived from the overall analysis of the data:\n",
    "    1. Overfitting may happen due to the insufficient training data set.\n",
    "    2. Filter methods may fail to find the best subset of features in situations when there is not enough data to model the statistical correlation of the features, but wrapper methods can always provide the best subset of features because of their exhaustive nature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
